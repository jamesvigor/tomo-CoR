{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomographic Reconstruction: Centre of Rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a successful reconstruction we need `matplotlib` for visualisation and debugging, `numpy` for array manipulation, `tomopy` so we can import `tomocuda`, `tomocuda` to run correction algorithms on a GPU, write_centerfrom `tomopy.recon.rotation` to write individual slices to disk with varying centres of rotation, and the `algorithm` function from `tomopy.recon.algorithm`. We take `dxchange` to read and write data from and to disk and `datetime` for benchmarking our processing speed, `os` is used for `os.path.join`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import tomopy\n",
    "import tomocuda\n",
    "from tomopy.recon.rotation import write_center\n",
    "from tomopy.recon.algorithm import recon\n",
    "import dxchange as tir\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by setting some basic directory information for input and output. An unreconstructed tomographic image series is required `file` (radiographs of the sample through 360 deg.), and a dark current `file_dark` and open beam `file_flat` image. These are contained within `data_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir  = '' # Input data directory\n",
    "file      = '' # Input file in data directory\n",
    "file_flat = '' # Open beam file\n",
    "file_dark = '' # Dark current file\n",
    "\n",
    "output_dir  = data_dir\n",
    "file_name   = os.path.join(data_dir, file)\n",
    "flat_name   = os.path.join(data_dir, file_flat)\n",
    "dark_name   = os.path.join(data_dir, data_dark)\n",
    "output_file = '{}/recon_{}/recon_{}_'.format(output_dir, file.split(\".\")[-2], file.split(\".\")[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load our data into memory using the `tir` module. The 2-BM instrument provides data in the HDF5 file format, so we use the appropriate function to load the file. `data` contains our raw input file, the radiographic series. `white` contains out open beam data, and `dark` contains the dark current image. NOTE: the 2-BM instrument is configured to write data to `exchange/data_dark` regardless of the acquisition type, this is not an error. The volume is cropped here; the full height of the radiograph is not required until a full reconstruction is run. This makes the process more rapid and reduces the memory requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are taking the third tomographic scan in this series. In each scan we write 600 radiographs to the hard disk (start 0 to 599, 600 to 1200, 1200 to 1800, 1800 to 2400 and so on and so forth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = tir.read_hdf5(file_name, 'exchange/data_dark', slc=((1800,2400), (700,720,1)))\n",
    "white = tir.read_hdf5(flat_mame, 'exchange/data_dark', slc=((1,9),       (700,720,1)))\n",
    "dark  = tir.read_hdf5(dark_name, 'exchange/data_dark', slc=((1,9),       (700,720,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the data set is required, and the theta value for each rotational position is determined using the numpy `linspace` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = data.shape\n",
    "theta     = np.linspace(0, np.pi, num=data_size[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now outliers are removed from the raw data and open beam acquisitions. Outliers are not removed from the dark current data as these are outliers by definition. This is carried out using the `tomocuda` package which uses the NVIDIA CUDA interface. The outlier level is defined as 200. This is a slow operation, and we can optionally save to disk here to prevent us having to re-execute this if a mistake is made further on. The following cell can re-load the data if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_level = 200\n",
    "data  = tomocuda.remove_outlier_cuda(data,  outlier_level, size=15)\n",
    "white = tomocuda.remove_outlier_cuda(white, outlier_level, size=15)\n",
    "\n",
    "# np.savez('data.npz', data)\n",
    "# np.savez('white.npz', white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data  = np.load('data.npz')\n",
    "# white = np.load('white.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are now corrected for scintillator artefacts using the open beam signal and systematic (non-variable) noise using the dark current data. The first slice becomes corrupt by this so we remove it (reason unknown, probably the source code of tomopy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tomopy.prep.normalize(data, white, dark) # Correct for dark current and open beam\n",
    "data = tomopy.prep.normalize_bg(data, air=10)   # Normalize the background to 10\n",
    "data[0,:,:] = data[1,:,:]                       # Remove the corrupted first slice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stripes are now removed using the Fourier Wavelet method. This is rapid; we can do this using the CPU. `level` is the number of discrete transformatio  levels, `wname` is the type of filter, `sigma` is the damping parameter, `pad` pads the sinogram with zeros. Run on 4 cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tomopy.prep.stripe.remove_stripe_fw(data,\n",
    "                                           level = 6,\n",
    "                                           wname = 'sym16'\n",
    "                                           sigma = 2,\n",
    "                                           pad   = True,\n",
    "                                           ncore = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the phase contrast is extracted and merged with the absorption contrast by the regularisation parameter set in `rat`. This is set, and then left identical for <b>all</b> reconstructions we are carrying out to ensure a consistent method. The array is padded with zeros, we've got a 27 keV incident beam and the PCO Dimax camera has a pixel size of 11 um. Our propagation length is 10 cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat        = 0.1e-2 # Regularisation Parameter\n",
    "pixel_size = 0.0011 # Detector Pixel Size in cm (PCO Dimax)\n",
    "eng        = 27     # Incident beam energy in keV\n",
    "z          = 10     # Wavefront Propagation Distance in cm\n",
    "\n",
    "data = tomopy.prep.phase.retrieve_phase(data, \n",
    "                                        pixel_size=pxl, \n",
    "                                        dist=z, \n",
    "                                        energy=eng, \n",
    "                                        alpha=rat, \n",
    "                                        pad=True,\n",
    "                                        ncore=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to reconstruct and write the data to disk. we only need a single slice to reconstruct and find the center of rotation, so we trim our dataset down once again to this. The `cen_range` tuple is the range of values over which the center of rotation is expected, approximately half way through the image, and the delta value which sets our precision. Once written to disk this can be loaded into a package such as imagej and searched for the correct center of rotation value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_center(data[:,19:21,:], theta, dpath=output_dir, cen_range=(2000, 2500, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this, we can adjust the `cen_range` parameter and refine further and further down to give a more and more precise location."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
